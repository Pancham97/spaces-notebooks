{"cells":[{"attachments":{},"cell_type":"markdown","id":"1744aa42-1d83-4ffe-9633-34bca98f537c","metadata":{"language":"python"},"source":"# Unified Data Analysis: SQL & NoSQL on a Single Database with Kai"},{"attachments":{},"cell_type":"markdown","id":"7f3d6b1c-9365-4113-8963-6aeaf08efbd2","metadata":{"language":"sql"},"source":"<img src=https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/notebooks/unified-data-analysis-sql-nosql-kai/banking_analytics.png width=\"100%\">"},{"attachments":{},"cell_type":"markdown","id":"cacc9529-3715-4854-8d7f-05543df12c15","metadata":{"language":"sql"},"source":"### What you will learn in this notebook:\n\nIn this notebook we ingest data from from different sources like MySQL, MongoDB and S3 and perform efficient analysis using both NoSQL and SQL on multimodal data (tabular and JSON). \n\n### Highlights\n1. Setup CDC from MongoDB and MySQL in easy steps. Replicate data in real-time and ensure upto date information for analytics, eliminating the need for complex tooling for data movement\n\n2. Analyze data using both NoSQL and relational approaches, depending on your specific needs. Developers and data analytics who are familiar with different programming approaches like MongoDB query language and SQL can work together on the same database. Perform familiar SQL queries on your NoSQL data!\n\nReady to unlock real-time analytics and unified data access? Let's start!"},{"cell_type":"code","execution_count":696,"id":"e87ac44e-ff79-466f-9c17-9f9667ad8089","metadata":{"execution":{"iopub.execute_input":"2024-02-20T16:15:20.397612Z","iopub.status.busy":"2024-02-20T16:15:20.397349Z","iopub.status.idle":"2024-02-20T16:15:22.047207Z","shell.execute_reply":"2024-02-20T16:15:22.046405Z","shell.execute_reply.started":"2024-02-20T16:15:20.397597Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Note: you may need to restart the kernel to use updated packages.\n"}],"source":"pip install pymongo prettytable matplotlib --quiet"},{"attachments":{},"cell_type":"markdown","id":"10a03a4a-2cfa-4ecd-b2ef-97c6bfa6f755","metadata":{"execution":{"iopub.execute_input":"2024-01-29T16:59:36.779382Z","iopub.status.busy":"2024-01-29T16:59:36.778995Z","iopub.status.idle":"2024-01-29T16:59:36.788503Z","shell.execute_reply":"2024-01-29T16:59:36.787962Z","shell.execute_reply.started":"2024-01-29T16:59:36.779362Z"},"language":"sql"},"source":"### Create database for importing data from different sources \n\nThis example gets banking data from three different sources: ATM locations from S3, transaction data from MySQL and user profile details from MongoDB databases. Joins data from different sources to generate rich insights about the transactional activity across user profile and locations across the globe"},{"cell_type":"code","execution_count":null,"id":"d0463f3f-419a-4a4b-be77-ef02a027f8aa","metadata":{"language":"sql","scrolled":true,"trusted":true},"outputs":[],"source":"%%sql\nDROP DATABASE IF EXISTS BankingAnalytics;\nCREATE DATABASE BankingAnalytics;"},{"attachments":{},"cell_type":"markdown","id":"a3335e3a-1fad-4857-975d-81d4a5205f08","metadata":{"language":"sql"},"source":"<div class=\"alert alert-block alert-warning\">\n    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n    <div>\n        <p><b>Action Required</b></p>\n        <p> Make sure to select 'BankingAnalytics' database from the drop-down menu at the top of this notebook. It updates the <tt>connection_url</tt>  to connect to that database.</p>\n    </div>\n</div>"},{"cell_type":"markdown","id":"ff27f40c-4d92-4597-91d8-5e2c43ed32ed","metadata":{"language":"python"},"source":"<img src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/notebooks/unified-data-analysis-sql-nosql-kai/selectdb.png\" style=\"width: 500px; border: 1px solid darkorchid\"> "},{"attachments":{},"cell_type":"markdown","id":"629241ce-8464-4834-bad3-3f88af675e59","metadata":{"language":"sql"},"source":"## Setup CDC from MySQL"},{"attachments":{},"cell_type":"markdown","id":"e99f3b06-82d3-47d0-a3f9-d93d08f3e9a2","metadata":{"language":"python"},"source":"### Singlestore allows you to ingest the data from mysql using pipelines . "},{"attachments":{},"cell_type":"markdown","id":"1807cb20-ddc8-4f8c-97c0-c473e8049768","metadata":{"language":"sql"},"source":"In this step , we will create sqllink and create the pipelines to infer the schema and start the cdc "},{"cell_type":"code","execution_count":null,"id":"37cf747a-286b-4f37-8d8a-7b191fec1366","metadata":{"language":"sql","trusted":true},"outputs":[],"source":"%%sql\ncreate link mysqllink as mysql config\n'{\"database.hostname\": \"3.141.19.255\",\n\"database.exclude.list\": \"mysql,performance_schema\", \"table.include.list\": \"DomainAnalytics.transactions\",\"database.port\": 3306, \"database.ssl.mode\":\"required\"}'\ncredentials '{\"database.password\": \"Password@123\", \"database.user\": \"repl_user\"}';"},{"cell_type":"code","execution_count":null,"id":"da44f747-85c0-400b-b155-be55c860f076","metadata":{"language":"sql","trusted":true},"outputs":[],"source":"%%sql\ncreate tables as infer pipeline as load data link\nmysqllink \"*\" format avro;"},{"cell_type":"code","execution_count":null,"id":"4b230ff8-913a-4f67-83d7-778a514f8136","metadata":{"language":"sql","trusted":true},"outputs":[],"source":"%%sql\nSTART ALL PIPELINES;"},{"attachments":{},"cell_type":"markdown","id":"af22186a-9989-4a73-8adc-6d8532c70cd6","metadata":{"language":"sql"},"source":"### Migrate the data from S3 storage to SingleStore using Pipelines"},{"attachments":{},"cell_type":"markdown","id":"4d51519a-9e5e-43cd-95bd-07f4b59f80c7","metadata":{"execution":{"iopub.execute_input":"2024-02-20T16:04:13.220182Z","iopub.status.busy":"2024-02-20T16:04:13.219906Z","iopub.status.idle":"2024-02-20T16:04:13.236718Z","shell.execute_reply":"2024-02-20T16:04:13.236272Z","shell.execute_reply.started":"2024-02-20T16:04:13.220166Z"},"language":"sql"},"source":" We are migrating the data from S3 using pipelines, you will require to create tables before hand "},{"cell_type":"code","execution_count":null,"id":"82260c10-9482-4997-8208-5a8d6bff48d2","metadata":{"language":"sql","trusted":true},"outputs":[],"source":"%%sql\nCREATE TABLE IF NOT EXISTS atm_locations (\n    id INT PRIMARY KEY,\n    name VARCHAR(255),\n    address VARCHAR(255),\n    city VARCHAR(255),\n    country VARCHAR(255),\n    latitude DECIMAL(9, 6),\n    longitude DECIMAL(9, 6)\n);"},{"cell_type":"code","execution_count":null,"id":"689ec731-2a2a-4035-9dc3-fead074240cc","metadata":{"language":"sql","trusted":true},"outputs":[],"source":"%%sql\nCREATE PIPELINE atmlocations AS\nLOAD DATA S3 's3://ocbfinalpoc1/data'\nCONFIG '{\"region\":\"ap-southeast-1\"}'\nSKIP DUPLICATE KEY ERRORS\nINTO TABLE atm_locations;"},{"cell_type":"code","execution_count":null,"id":"5c482f6a-c053-438e-a671-a3a7894052a7","metadata":{"language":"sql","trusted":true},"outputs":[],"source":"%%sql\nstart pipeline atmlocations"},{"attachments":{},"cell_type":"markdown","id":"806952a2-090c-48aa-a1e4-8c71cd66143d","metadata":{"execution":{"iopub.execute_input":"2024-01-25T15:37:26.504837Z","iopub.status.busy":"2024-01-25T15:37:26.504596Z","iopub.status.idle":"2024-01-25T15:37:26.521096Z","shell.execute_reply":"2024-01-25T15:37:26.520693Z","shell.execute_reply.started":"2024-01-25T15:37:26.504822Z"},"language":"sql"},"source":"### Setup CDC from MongoDB to SingleStore"},{"attachments":{},"cell_type":"markdown","id":"1c2d83fa-6a94-4a2b-a657-0e3f8ea0bf8b","metadata":{"language":"sql"},"source":"We will create pipelines to migrate the data from mongo to Singlestore \n\nPlease note that , Singlstore has capability to infer the schema from mongo db into Singlestore"},{"cell_type":"code","execution_count":null,"id":"fb852b9c-51a6-4d8c-a4a2-f0cb6e78dc60","metadata":{"language":"sql","trusted":true},"outputs":[],"source":"%%sql\nCREATE link mongo AS MONGODB\nCONFIG '{\"mongodb.hosts\":\"ac-t7n47to-shard-00-00.tfutgo0.mongodb.net:27017,ac-t7n47to-shard-00-01.tfutgo0.mongodb.net:27017,ac-t7n47to-shard-00-02.tfutgo0.mongodb.net:27017\",\n         \"collection.include.list\": \"bank.*\",\n         \"mongodb.ssl.enabled\":\"true\",\n         \"mongodb.authsource\":\"admin\",\n         \"mongodb.members.auto.discover\": \"true\"}'\nCREDENTIALS '{\"mongodb.user\":\"forimport\",\n              \"mongodb.password\":\"4Zfb0SKGCcDz5bBt\"}';"},{"cell_type":"code","execution_count":null,"id":"ae958c77-2e84-4434-9dcd-205837bd5f02","metadata":{"language":"sql","trusted":true},"outputs":[],"source":"%%sql\nCREATE TABLES AS INFER PIPELINE AS LOAD DATA link mongo '*' FORMAT AVRO;"},{"cell_type":"code","execution_count":null,"id":"32b32f1e-072b-4273-952b-6772b4a8e380","metadata":{"language":"sql","trusted":true},"outputs":[],"source":"%%sql\nshow pipelines"},{"cell_type":"code","execution_count":null,"id":"3a91eefe-6d82-453b-8d3d-10344baae466","metadata":{"language":"sql","trusted":true},"outputs":[],"source":"%%sql\nSTART ALL PIPELINES"},{"attachments":{},"cell_type":"markdown","id":"c0d54948-e440-43f7-963b-8d6b2c1b6129","metadata":{"language":"sql"},"source":"### Check for records in tables"},{"attachments":{},"cell_type":"markdown","id":"e45a1cb9-d884-4ac5-91dd-c8ded628bcb0","metadata":{"language":"sql"},"source":"1. Data from MySQL"},{"cell_type":"code","execution_count":null,"id":"c288f83a-9495-4baa-940f-9fe8400ab93b","metadata":{"language":"sql","trusted":true},"outputs":[],"source":"%%sql\nselect count(*) from transactions"},{"cell_type":"code","execution_count":null,"id":"f8604704-9324-4630-9eec-2c3f6be3c853","metadata":{"language":"sql","trusted":true},"outputs":[],"source":"%%sql\nSELECT * FROM transactions WHERE transaction_type LIKE '%Deposit%' LIMIT 1;"},{"attachments":{},"cell_type":"markdown","id":"0a39438a-a537-490e-9191-77c9b224bbb4","metadata":{"language":"sql"},"source":"2. Data from S3 "},{"cell_type":"code","execution_count":null,"id":"5d26d20e-ef26-4d73-8a6a-060716e5f5ae","metadata":{"language":"sql","trusted":true},"outputs":[],"source":"%%sql\nselect count(*) from atm_locations"},{"cell_type":"code","execution_count":null,"id":"62eced11-86b7-4c66-a7a8-ad197460e99d","metadata":{"language":"sql","trusted":true},"outputs":[],"source":"%%sql\nSELECT * FROM atm_locations LIMIT 1;"},{"attachments":{},"cell_type":"markdown","id":"a06fc97a-59ec-4134-a3cf-016b39108374","metadata":{"execution":{"iopub.execute_input":"2024-02-20T15:14:11.696639Z","iopub.status.busy":"2024-02-20T15:14:11.696391Z","iopub.status.idle":"2024-02-20T15:14:11.704739Z","shell.execute_reply":"2024-02-20T15:14:11.704023Z","shell.execute_reply.started":"2024-02-20T15:14:11.696623Z"},"language":"sql"},"source":"3. Data from MongoDB"},{"cell_type":"code","execution_count":null,"id":"40c77598-464b-4d91-b36e-89569e1ecb12","metadata":{"language":"sql","scrolled":true,"trusted":true},"outputs":[],"source":"%%sql\nSELECT _id:>JSON, _more:>JSON FROM profile LIMIT 1;"},{"cell_type":"code","execution_count":null,"id":"a4694186-b064-465f-9e4f-9a33b1d6ae76","metadata":{"language":"sql","trusted":true},"outputs":[],"source":"%%sql\n\nSELECT _id:>JSON, _more:>JSON FROM history LIMIT 1;"},{"attachments":{},"cell_type":"markdown","id":"40ec6ef2-dd95-43b7-947a-16c80efc359a","metadata":{"language":"sql"},"source":"### Join tables from different sources using SQL queries "},{"attachments":{},"cell_type":"markdown","id":"3bfb62de-ae36-4824-881f-c858cb852c01","metadata":{"language":"sql"},"source":"SQL Query 1: View Users details, their associated ATMs "},{"cell_type":"code","execution_count":null,"id":"9efacacd-b36e-4208-a360-3ca239d1fad3","metadata":{"language":"sql","trusted":true},"outputs":[],"source":"%%sql\nSELECT\n    p._more::$full_name AS NameOfPerson,\n    p._more::$email AS Email,\n    a.id,\n    a.name AS ATMName,\n    a.city,\n    a.country\nFROM\n    profile p,\n    atm_locations a\nWHERE\n    p._more::$account_id = a.id limit 10;"},{"attachments":{},"cell_type":"markdown","id":"2cce1897-681f-4136-807e-711ed78ed80b","metadata":{"language":"sql"},"source":"SQL Query 2: View Users details, their associated ATMs and transaction details"},{"cell_type":"code","execution_count":null,"id":"82d52f1a-35e8-4f59-99ed-cbd65842f699","metadata":{"language":"sql","trusted":true},"outputs":[],"source":"%%sql\nSELECT\n    p._more::$full_name AS NameOfPerson,\n    p._more::$email AS Email,\n    a.id,\n    a.name AS ATMName,\n    a.city,\n    t.transaction_id,\n    t.transaction_date,\n    t.amount,\n    t.transaction_type,\n    t.description\nFROM\n    profile p\nJOIN\n    atm_locations a ON p._more::$account_id = a.id\nLEFT JOIN\n    transactions t ON p._more::$account_id = t.account_id limit 10;\n"},{"attachments":{},"cell_type":"markdown","id":"2fb24ac0-1579-4ddb-8009-efb36aaff2d6","metadata":{"language":"python"},"source":"### Run queries in Mongo Query Language using Kai"},{"cell_type":"code","execution_count":null,"id":"d7f5fa93-473e-4e0b-96ca-e743cb75684d","metadata":{"language":"python","trusted":true},"outputs":[],"source":"from pymongo import MongoClient\nimport pprint\nfrom prettytable import PrettyTable\n\nclient = MongoClient(connection_url_mongo)\n\n# Get the profile collection\n\ndb = client['BankingAnalytics']\n\nprofile_coll = db['profile']\n\nfor profile in profile_coll.find().limit(1):\n  pprint.pprint(profile)"},{"cell_type":"code","execution_count":null,"id":"dd303812-2ec2-4e84-b436-617591099a06","metadata":{"language":"python","trusted":true},"outputs":[],"source":"pipeline = [\n    {\n        \"$lookup\": {\n            \"from\": \"profile\",\n            \"localField\": \"account_id\",\n            \"foreignField\": \"account_id\",\n            \"as\": \"profile_data\"\n        }\n    },\n    {\n        \"$limit\": 5\n    },\n    {\n        \"$group\": {\n            \"_id\": \"$_id\",\n            \"history_data\": {\"$first\": \"$$ROOT\"},\n            \"profile_data\": {\"$first\": {\"$arrayElemAt\": [\"$profile_data\", 0]}}\n        }\n    },\n    {\n        \"$project\": {\n            \"_id\": \"$history_data._id\",\n            \"account_id\": \"$history_data.account_id\",\n            \"history_data\": \"$history_data\",\n            \"profile_data\": \"$profile_data\"\n        }\n    }\n]\n\n# Execute the aggregation pipeline\nresult = list(db.history.aggregate(pipeline))\n\n# Print the result in a tabular format\ntable = PrettyTable([\"Account ID\", \"Full Name\", \"Date of Birth\", \"City\", \"State\", \"Country\", \"Postal Code\", \"Phone Number\", \"Email\"])\nfor doc in result:\n    profile_data = doc[\"profile_data\"]\n    table.add_row([\n        doc[\"account_id\"],\n        profile_data.get(\"full_name\", \"\"),\n        profile_data.get(\"date_of_birth\", \"\"),\n        profile_data.get(\"city\", \"\"),\n        profile_data.get(\"state\", \"\"),\n        profile_data.get(\"country\", \"\"),\n        profile_data.get(\"postal_code\", \"\"),\n        profile_data.get(\"phone_number\", \"\"),\n        profile_data.get(\"email\", \"\")\n    ])\n\nprint(table)"},{"cell_type":"code","execution_count":null,"id":"00e2c386-2ae5-478d-be0a-c9c07005745e","metadata":{"language":"python","trusted":true},"outputs":[],"source":"# Get the state with highest number of customers\nfrom bson.son import SON\n\npipeline = [\n    {\"$group\": {\"_id\": \"$state\", \"count\": {\"$sum\": 1}}},\n    {\"$sort\": SON([(\"count\", -1), (\"_id\", -1)])},\n    {\"$limit\": 5}\n]\n\np1 = [\n    {\"$count\": \"count\"}\n]\npprint.pprint(list(profile_coll.aggregate(pipeline)))"},{"cell_type":"code","execution_count":null,"id":"a0e0be36-0605-426b-a84a-1c47bab2f7cb","metadata":{"language":"python","scrolled":true,"trusted":true},"outputs":[],"source":"import matplotlib.pyplot as plt\n\ndata = list(profile_coll.aggregate(pipeline))\n\nprint(data)\n\ncountry,count = [dcts['_id'] for dcts in data],[dcts['count'] for dcts in data]\n\nplt.bar(country,count)\nplt.plot()"}],"metadata":{"jupyterlab":{"notebooks":{"version_major":6,"version_minor":4}},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"13ebe7f2-c43c-445a-b199-0f92cda345a4","defaultDatabase":"BankingAnalytics"}},"nbformat":4,"nbformat_minor":5}